{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5456,
     "status": "ok",
     "timestamp": 1738871387348,
     "user": {
      "displayName": "HAREL ARATH HERNANDEZ AMEZCUA",
      "userId": "16374506728272450130"
     },
     "user_tz": 360
    },
    "id": "5wUhVvOx00qF",
    "outputId": "8ddc7291-9e50-4792-9f6f-3abfcba4030a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install certifi==2022.6.15 charset-normalizer==2.1.1 imageio==2.21.1 jmespath==1.0.1 joblib==1.1.1 networkx==2.8.6 numpy==1.23.5 opencv-python-headless==4.7.0.72 \\\n",
    "    packaging==21.3 Pillow==9.4.0 \"protobuf>3.8,<=3.20.12\" pyparsing==3.0.9 pyrr==0.10.3 python-dateutil==2.8.2 PyWavelets==1.5.0 PyYAML==6.0 qudida==0.0.4 requests==2.28.1 \\\n",
    "    scikit-image==0.20.0 scikit-learn==1.2.2 scipy==1.10.1 simplejson==3.18.4 six==1.16.0 tensorboardX==2.5.1 threadpoolctl==3.1.0 tifffile==2022.8.12 typing_extensions==4.3.0 \\\n",
    "    urllib3==1.26.12 boto3==1.24.58 botocore==1.27.58 s3transfer==0.6.0 torch==2.0.1 torchvision==0.15.2 albumentations[imgaug]==1.2.1\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8919,
     "status": "ok",
     "timestamp": 1738871401208,
     "user": {
      "displayName": "HAREL ARATH HERNANDEZ AMEZCUA",
      "userId": "16374506728272450130"
     },
     "user_tz": 360
    },
    "id": "22Mj3pai6Xk3",
    "outputId": "fd993ff6-58f6-49ac-e9bd-0562186be739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "from math import pi\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import albumentations as A\n",
    "\n",
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Conditional that checks if its running on colab and if so change the directory to the correct one\n",
    "if 'google.colab' in sys.modules:\n",
    "    os.chdir('/content/drive/MyDrive/dope-training')\n",
    "    print(\"Running on Google Colab\")\n",
    "else:        \n",
    "\n",
    "    # Get the current directory\n",
    "    current_dir = Path.cwd()\n",
    "\n",
    "    # Add all parent directories to the system path\n",
    "    for parent in current_dir.parents:\n",
    "        sys.path.append(str(parent))\n",
    "\n",
    "from auxiliar_dope.model import DopeNetwork\n",
    "from auxiliar_dope.utils import MultipleVertexJson, save_image\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "\n",
    "\n",
    "full_path = os.getcwd()\n",
    "if full_path not in sys.path:\n",
    "    sys.path.append(full_path)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\github\\dope-training\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import src.args_parser as ar\n",
    "\n",
    "opt = ar.parse_args(full_path)\n",
    "\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1556,
     "status": "ok",
     "timestamp": 1738871442052,
     "user": {
      "displayName": "HAREL ARATH HERNANDEZ AMEZCUA",
      "userId": "16374506728272450130"
     },
     "user_tz": 360
    },
    "id": "9a31RWTP8d0k",
    "outputId": "55d6aa95-0ded-460e-f0f1-4c3b3e6004c7"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# TRAINING CODE MAIN STARTING HERE\n",
    "##################################################\n",
    "\n",
    "print (\"start:\" , datetime.datetime.now().time())\n",
    "\n",
    "conf_parser = argparse.ArgumentParser(\n",
    "    description=__doc__, # printed with -h/--help\n",
    "    # Don't mess with format of description\n",
    "    formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    # Turn off help, so we print all options in response to -h\n",
    "    add_help=False\n",
    "    )\n",
    "conf_parser.add_argument(\"-c\", \"--config\",\n",
    "                        help=\"Specify config file\", metavar=\"FILE\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--data',\n",
    "    default =  \"/content/drive/Othercomputers/Mi portátil/dataset\",\n",
    "    help='path to training data')\n",
    "\n",
    "parser.add_argument('--datatest',\n",
    "    default= \"/content/drive/MyDrive/dope-training/test_Data\",\n",
    "    help='path to data testing set')\n",
    "\n",
    "parser.add_argument('--object',\n",
    "    default=\"60\",\n",
    "    help='In the dataset which object of interest')\n",
    "\n",
    "parser.add_argument('--workers',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='number of data loading workers')\n",
    "\n",
    "parser.add_argument('--batchsize',\n",
    "    type=int,\n",
    "    default=64,\n",
    "    help='input batch size')\n",
    "\n",
    "parser.add_argument('--subbatchsize',\n",
    "    type=int,\n",
    "    default=16,\n",
    "    help='input batch size')\n",
    "\n",
    "parser.add_argument('--imagesize',\n",
    "    type=int,\n",
    "    default=400,\n",
    "    help='the height / width of the input image to network')\n",
    "\n",
    "parser.add_argument('--lr',\n",
    "    type=float,\n",
    "    default=0.0001,\n",
    "    help='learning rate, default=0.0001')\n",
    "\n",
    "parser.add_argument('--noise',\n",
    "    type=float,\n",
    "    default=0.7,\n",
    "    help='gaussian noise added to the image')\n",
    "\n",
    "parser.add_argument('--net',\n",
    "    default=os.path.join(full_path, \"weights/net.pth\"),\n",
    "    help=\"path to net (to continue training)\")\n",
    "\n",
    "parser.add_argument('--namefile',\n",
    "    default='weights_mustard',\n",
    "    help=\"name to put on the file of the save weights\")\n",
    "\n",
    "parser.add_argument('--manualseed',\n",
    "    type=int,\n",
    "    help='manual seed')\n",
    "\n",
    "parser.add_argument('--epochs',\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help=\"number of epochs to train\")\n",
    "\n",
    "parser.add_argument('--loginterval',\n",
    "    type=int,\n",
    "    default=100)\n",
    "\n",
    "parser.add_argument('--gpuids',\n",
    "    nargs='+',\n",
    "    type=int,\n",
    "    default=[0],\n",
    "    help='GPUs to use')\n",
    "\n",
    "parser.add_argument('--outf',\n",
    "    default=os.path.join(full_path, \"out\"),\n",
    "    help='folder to output images and model checkpoints, it will \\\n",
    "    add a train_ in front of the name')\n",
    "\n",
    "parser.add_argument('--sigma',\n",
    "    default=8,\n",
    "    help='keypoint creation size for sigma')\n",
    "\n",
    "parser.add_argument('--save',\n",
    "    default = True,\n",
    "    help='save a visual batch and quit, this is for\\\n",
    "    debugging purposes')\n",
    "\n",
    "parser.add_argument(\"--pretrained\",\n",
    "    default=True,\n",
    "    help='do you want to use vgg imagenet pretrained weights')\n",
    "\n",
    "parser.add_argument('--nbupdates',\n",
    "    default=None,\n",
    "    help='nb max update to network, overwrites the epoch number\\\n",
    "    otherwise uses the number of epochs')\n",
    "\n",
    "parser.add_argument('--datasize',\n",
    "    default=None,\n",
    "    help='randomly sample that number of entries in the dataset folder')\n",
    "\n",
    "# Read the config but do not overwrite the args written\n",
    "args, remaining_argv = conf_parser.parse_known_args()\n",
    "defaults = { \"option\":\"default\" }\n",
    "\n",
    "if args.config:\n",
    "    config = configparser.SafeConfigParser()\n",
    "    config.read([args.config])\n",
    "    defaults.update(dict(config.items(\"defaults\")))\n",
    "\n",
    "parser.set_defaults(**defaults)\n",
    "parser.add_argument(\"--option\")\n",
    "\n",
    "# Parse known arguments\n",
    "opt, unknown = parser.parse_known_args(remaining_argv)\n",
    "\n",
    "if opt.pretrained in ['false', 'False']:\n",
    "\topt.pretrained = False\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.outf)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if opt.manualseed is None:\n",
    "    opt.manualseed = random.randint(1, 10000)\n",
    "\n",
    "# save the hyper parameters passed\n",
    "with open (opt.outf+'/header.txt','w') as file:\n",
    "    file.write(str(opt)+\"\\n\")\n",
    "\n",
    "with open (opt.outf+'/header.txt','w') as file:\n",
    "    file.write(str(opt))\n",
    "    file.write(\"seed: \"+ str(opt.manualseed)+'\\n')\n",
    "    with open (opt.outf+'/test_metric.csv','w') as file:\n",
    "        file.write(\"epoch, passed,total \\n\")\n",
    "\n",
    "# set the manual seed.\n",
    "random.seed(opt.manualseed)\n",
    "torch.manual_seed(opt.manualseed)\n",
    "torch.cuda.manual_seed_all(opt.manualseed)\n",
    "\n",
    "additional_targets = {\n",
    "    'centroids': 'keypoints'\n",
    "}\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def scale_down(x, **kwargs):\n",
    "    return cv2.resize(x, (x.shape[0] // 8, x.shape[1] // 8))\n",
    "\n",
    "\n",
    "img_size = (480,640)\n",
    "\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271,
     "referenced_widgets": [
      "ffc52002add049fa821a489101fa989d",
      "579123a0c14a4e55a1f7b8e7ced6d3ca",
      "e23a0bdec01a4cb4b87085ea35cc766d",
      "edb1790707c24c1e91aa985a6f891525",
      "ad02181804db4ef983120cdfb95118fd",
      "91bdd8f3521746518cb0c39cb2868280",
      "b433b937dd814db6a4c370ffcbdfd35c",
      "64ae4cc5cf1a491b946adc073cc64a01",
      "88928f7e8ab545f0826c30e4300a87e8",
      "c2d9daeaeadc4f4ab34f40ed8e5c54cc",
      "cf03ede67be541c083803b9158899002"
     ]
    },
    "id": "oN2AdOmJ8jUU",
    "outputId": "b0c480fe-c441-438a-d776-f5a65586cf36"
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=0.1, shift_limit=0.1, p=0.1, border_mode=0),\n",
    "\n",
    "    A.RandomCrop(height=img_size[0], width=img_size[1]),\n",
    "\n",
    "    A.IAAAdditiveGaussianNoise(p=0.2),\n",
    "    A.IAAPerspective(p=0.5),\n",
    "\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.CLAHE(p=1),\n",
    "            A.RandomBrightness(p=1),\n",
    "            A.RandomGamma(p=1),\n",
    "        ],\n",
    "        p=0.9,\n",
    "    ),\n",
    "\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.IAASharpen(p=1),\n",
    "            A.Blur(blur_limit=3, p=1),\n",
    "            A.MotionBlur(blur_limit=3, p=1),\n",
    "        ],\n",
    "        p=0.9,\n",
    "    ),\n",
    "\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.RandomContrast(p=1),\n",
    "            A.HueSaturationValue(p=1),\n",
    "        ],\n",
    "        p=0.9,\n",
    "    )],\n",
    "additional_targets=additional_targets,\n",
    "keypoint_params=A.KeypointParams(\"xy\", remove_invisible=False))\n",
    "\n",
    "preprocessing_transform = A.Compose([\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        A.Lambda(mask=scale_down),\n",
    "        A.Lambda(image=to_tensor, mask=to_tensor)],\n",
    "    additional_targets=additional_targets,\n",
    "    keypoint_params=A.KeypointParams(\"xy\", remove_invisible=False))\n",
    "\n",
    "\n",
    "\n",
    "#load the dataset using the loader in utils_pose\n",
    "trainingdata = None\n",
    "if not opt.data == \"\":\n",
    "    train_dataset = MultipleVertexJson(\n",
    "        root = opt.data,\n",
    "        preprocessing_transform=preprocessing_transform,\n",
    "        objectsofinterest=opt.object,\n",
    "        sigma = opt.sigma,\n",
    "        data_size = opt.datasize,\n",
    "        save = opt.save,\n",
    "        transform = transform\n",
    "    )\n",
    "\n",
    "    trainingdata = torch.utils.data.DataLoader(train_dataset,\n",
    "        batch_size = opt.subbatchsize,\n",
    "        shuffle = True,\n",
    "        num_workers = opt.workers,\n",
    "        pin_memory = True,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    train_dataset.test = True\n",
    "    \"\"\"for i in range(len(trainingdata)):\n",
    "        images = next(iter(trainingdata))\n",
    "\n",
    "        save_image(images['image'],'{}/train_{}.png'.format( opt.outf,str(i).zfill(5)),mean=mean[0],std=std[0])\n",
    "        print (\"Saving batch %d\" % i)\"\"\"\n",
    "    train_dataset.test = False\n",
    "\n",
    "    if opt.save:\n",
    "        print ('things are saved in {}'.format(opt.outf))\n",
    "        quit()\n",
    "\n",
    "\n",
    "testingdata = None\n",
    "if not opt.datatest == \"\":\n",
    "    test_dataset = MultipleVertexJson(\n",
    "            root = opt.datatest,\n",
    "            preprocessing_transform=preprocessing_transform,\n",
    "            objectsofinterest=opt.object,\n",
    "            sigma = opt.sigma,\n",
    "            data_size = opt.datasize,\n",
    "            save = opt.save,\n",
    "            test = True\n",
    "            )\n",
    "\n",
    "    testingdata = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = opt.subbatchsize // 2,\n",
    "        shuffle = True,\n",
    "        num_workers = opt.workers,\n",
    "        pin_memory = True,\n",
    "        drop_last=True)\n",
    "\n",
    "\n",
    "if not trainingdata is None:\n",
    "    print('training data: {} batches'.format(len(trainingdata)))\n",
    "if not testingdata is None:\n",
    "    print (\"testing data: {} batches\".format(len(testingdata)))\n",
    "\n",
    "net = DopeNetwork(pretrained=opt.pretrained)\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "if opt.net != '':\n",
    "    # Load state dict from file\n",
    "    state_dict = torch.load(opt.net, map_location='cuda')\n",
    "\n",
    "    # If the state dict keys start with \"module.\", remove that prefix\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "    # Use the new_state_dict directly\n",
    "    net.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.Adam(parameters,lr=opt.lr)\n",
    "\n",
    "with open (opt.outf+'/loss_train.csv','w') as file:\n",
    "    file.write('epoch,batchid,loss\\n')\n",
    "\n",
    "with open (opt.outf+'/loss_test.csv','w') as file:\n",
    "    file.write('epoch,batchid,loss\\n')\n",
    "\n",
    "nb_update_network = 0\n",
    "\n",
    "def _runnetwork(epoch, loader, train=True, scaler=None, pbar=None):\n",
    "    global nb_update_network\n",
    "    # net\n",
    "    if train:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "    for batch_idx, targets in enumerate(loader):\n",
    "\n",
    "        data = Variable(targets['image'].to(device).float())\n",
    "\n",
    "        with amp.autocast():\n",
    "            output_belief, output_affinities = net(data)\n",
    "\n",
    "            target_belief = Variable(targets['beliefs'].to(device).float())\n",
    "            target_affinity = Variable(targets['affinities'].to(device).float())\n",
    "\n",
    "            loss = None\n",
    "\n",
    "            for l in output_belief:\n",
    "                if loss is None:\n",
    "                    loss = ((l - target_belief) ** 2).mean()\n",
    "                else:\n",
    "                    loss += ((l - target_belief) ** 2).mean()\n",
    "\n",
    "\n",
    "            # Affinities loss\n",
    "            for l in output_affinities: #output, each belief map layers.\n",
    "                loss_tmp = ((l - target_affinity) * (l-target_affinity)).mean()\n",
    "                loss += loss_tmp\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if batch_idx % (opt.batchsize // opt.subbatchsize) == 0:\n",
    "                if train:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    nb_update_network+=1\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "        if train:\n",
    "            namefile = '/loss_train.csv'\n",
    "        else:\n",
    "            namefile = '/loss_test.csv'\n",
    "\n",
    "        with open (opt.outf+namefile,'a') as file:\n",
    "            s = '{}, {},{:.15f}\\n'.format(\n",
    "                epoch,batch_idx,loss.data.item())\n",
    "            # print (s)\n",
    "            file.write(s)\n",
    "\n",
    "        # break\n",
    "        if not opt.nbupdates is None and nb_update_network > int(opt.nbupdates):\n",
    "            torch.save(net.state_dict(), '{}/net_{}.pth'.format(opt.outf, opt.namefile))\n",
    "            break\n",
    "\n",
    "        if train:\n",
    "            if pbar is not None:\n",
    "                pbar.set_description(\"Training loss: %0.4f (%d/%d)\" % (loss.data.item(), batch_idx, len(loader)))\n",
    "        else:\n",
    "            if pbar is not None:\n",
    "                pbar.set_description(\"Testing loss: %0.4f (%d/%d)\" % (loss.data.item(), batch_idx, len(loader)))\n",
    "        if batch_idx % 10 == 0:\n",
    "          try:\n",
    "            torch.save(net.state_dict(), f'{opt.outf}/net.pth')\n",
    "            print(\"Guardando model\")\n",
    "          except Exception as e:\n",
    "            print(f\"Error saving model at epoch: {e}\")\n",
    "\n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "scaler = amp.GradScaler()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "pbar = tqdm(range(1, opt.epochs + 1))\n",
    "\n",
    "for epoch in pbar:\n",
    "    # Run training and testing as before\n",
    "    if trainingdata is not None:\n",
    "        _runnetwork(epoch, trainingdata, scaler=scaler, pbar=pbar)\n",
    "\n",
    "    if opt.datatest != \"\":\n",
    "        _runnetwork(epoch, testingdata, train=False, pbar=pbar)\n",
    "        if opt.data == \"\":\n",
    "            break  # Exit if only testing\n",
    "    try:\n",
    "        torch.save(net.state_dict(), f'{opt.outf}/net_{opt.namefile}_{epoch}.pth')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model at epoch {epoch}: {e}\")\n",
    "\n",
    "    # Stop training if nb_update_network exceeds the limit\n",
    "    if opt.nbupdates is not None and nb_update_network > int(opt.nbupdates):\n",
    "        break\n",
    "\n",
    "print(\"end:\", datetime.datetime.now().time())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (dope_venv)",
   "language": "python",
   "name": "dope_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "579123a0c14a4e55a1f7b8e7ced6d3ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91bdd8f3521746518cb0c39cb2868280",
      "placeholder": "​",
      "style": "IPY_MODEL_b433b937dd814db6a4c370ffcbdfd35c",
      "value": "Training loss: 0.0033 (30/313):   0%"
     }
    },
    "64ae4cc5cf1a491b946adc073cc64a01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88928f7e8ab545f0826c30e4300a87e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91bdd8f3521746518cb0c39cb2868280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad02181804db4ef983120cdfb95118fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b433b937dd814db6a4c370ffcbdfd35c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2d9daeaeadc4f4ab34f40ed8e5c54cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf03ede67be541c083803b9158899002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e23a0bdec01a4cb4b87085ea35cc766d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ae4cc5cf1a491b946adc073cc64a01",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88928f7e8ab545f0826c30e4300a87e8",
      "value": 0
     }
    },
    "edb1790707c24c1e91aa985a6f891525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d9daeaeadc4f4ab34f40ed8e5c54cc",
      "placeholder": "​",
      "style": "IPY_MODEL_cf03ede67be541c083803b9158899002",
      "value": " 0/10 [39:08&lt;?, ?it/s]"
     }
    },
    "ffc52002add049fa821a489101fa989d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_579123a0c14a4e55a1f7b8e7ced6d3ca",
       "IPY_MODEL_e23a0bdec01a4cb4b87085ea35cc766d",
       "IPY_MODEL_edb1790707c24c1e91aa985a6f891525"
      ],
      "layout": "IPY_MODEL_ad02181804db4ef983120cdfb95118fd"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
