{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6842,"status":"ok","timestamp":1740436178825,"user":{"displayName":"HAREL ARATH HERNANDEZ AMEZCUA","userId":"16374506728272450130"},"user_tz":360},"id":"5wUhVvOx00qF","outputId":"07d43dfd-f4ab-451c-9b56-fe1471151970"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: certifi==2022.6.15 in /usr/local/lib/python3.11/dist-packages (2022.6.15)\n","Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n","Requirement already satisfied: imageio==2.21.1 in /usr/local/lib/python3.11/dist-packages (2.21.1)\n","Requirement already satisfied: jmespath==1.0.1 in /usr/local/lib/python3.11/dist-packages (1.0.1)\n","Requirement already satisfied: joblib==1.1.1 in /usr/local/lib/python3.11/dist-packages (1.1.1)\n","Requirement already satisfied: networkx==2.8.6 in /usr/local/lib/python3.11/dist-packages (2.8.6)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n","Requirement already satisfied: opencv-python-headless==4.7.0.72 in /usr/local/lib/python3.11/dist-packages (4.7.0.72)\n","Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.11/dist-packages (21.3)\n","Requirement already satisfied: Pillow==9.4.0 in /usr/local/lib/python3.11/dist-packages (9.4.0)\n","Requirement already satisfied: protobuf<=3.20.12,>3.8 in /usr/local/lib/python3.11/dist-packages (3.20.1)\n","Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.11/dist-packages (3.0.9)\n","Requirement already satisfied: pyrr==0.10.3 in /usr/local/lib/python3.11/dist-packages (0.10.3)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.11/dist-packages (2.8.2)\n","Requirement already satisfied: PyWavelets==1.5.0 in /usr/local/lib/python3.11/dist-packages (1.5.0)\n","Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.11/dist-packages (6.0)\n","Requirement already satisfied: qudida==0.0.4 in /usr/local/lib/python3.11/dist-packages (0.0.4)\n","Requirement already satisfied: requests==2.28.1 in /usr/local/lib/python3.11/dist-packages (2.28.1)\n","Requirement already satisfied: scikit-image==0.20.0 in /usr/local/lib/python3.11/dist-packages (0.20.0)\n","Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n","Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (1.10.1)\n","Requirement already satisfied: simplejson==3.18.4 in /usr/local/lib/python3.11/dist-packages (3.18.4)\n","Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.11/dist-packages (1.16.0)\n","Requirement already satisfied: tensorboardX==2.5.1 in /usr/local/lib/python3.11/dist-packages (2.5.1)\n","Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: tifffile==2022.8.12 in /usr/local/lib/python3.11/dist-packages (2022.8.12)\n","Requirement already satisfied: typing_extensions==4.3.0 in /usr/local/lib/python3.11/dist-packages (4.3.0)\n","Requirement already satisfied: urllib3==1.26.12 in /usr/local/lib/python3.11/dist-packages (1.26.12)\n","Requirement already satisfied: boto3==1.24.58 in /usr/local/lib/python3.11/dist-packages (1.24.58)\n","Requirement already satisfied: botocore==1.27.58 in /usr/local/lib/python3.11/dist-packages (1.27.58)\n","Requirement already satisfied: s3transfer==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n","Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n","Requirement already satisfied: albumentations==1.2.1 in /usr/local/lib/python3.11/dist-packages (from albumentations[imgaug]==1.2.1) (1.2.1)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from pyrr==0.10.3) (1.0.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.28.1) (3.10)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.20.0) (0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.17.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.0.0)\n","Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from albumentations[imgaug]==1.2.1) (0.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (3.10.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (4.11.0.86)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (2.0.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations[imgaug]==1.2.1) (1.4.8)\n"]}],"source":["import sys\n","colab = False\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !pip install certifi==2022.6.15 charset-normalizer==2.1.1 imageio==2.21.1 jmespath==1.0.1 joblib==1.1.1 networkx==2.8.6 numpy==1.23.5 opencv-python-headless==4.7.0.72 \\\n","    packaging==21.3 Pillow==9.4.0 \"protobuf>3.8,<=3.20.12\" pyparsing==3.0.9 pyrr==0.10.3 python-dateutil==2.8.2 PyWavelets==1.5.0 PyYAML==6.0 qudida==0.0.4 requests==2.28.1 \\\n","    scikit-image==0.20.0 scikit-learn==1.2.2 scipy==1.10.1 simplejson==3.18.4 six==1.16.0 tensorboardX==2.5.1 threadpoolctl==3.1.0 tifffile==2022.8.12 typing_extensions==4.3.0 \\\n","    urllib3==1.26.12 boto3==1.24.58 botocore==1.27.58 s3transfer==0.6.0 torch==2.0.1 torchvision==0.15.2 albumentations[imgaug]==1.2.1\n","    colab = True"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14086,"status":"ok","timestamp":1740436192924,"user":{"displayName":"HAREL ARATH HERNANDEZ AMEZCUA","userId":"16374506728272450130"},"user_tz":360},"id":"22Mj3pai6Xk3","outputId":"240c32d1-d657-4a47-a3e5-3776645af0be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on Google Colab\n","Using device: cuda\n"]}],"source":["import argparse\n","import configparser\n","import datetime\n","import os\n","import random\n","import warnings\n","from collections import OrderedDict\n","from math import pi\n","from os.path import exists\n","from pathlib import Path\n","\n","import albumentations as A\n","import cv2\n","import torch\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable\n","from torch.cuda import amp\n","from tqdm.notebook import tqdm\n","\n","\n","# Conditional that checks if it's running on Colab and sets the directory accordingly\n","if colab:\n","    os.chdir('/content/drive/MyDrive/dope-training_new')\n","    print(\"Running on Google Colab\")\n","else:\n","    # Add all parent directories to the system path\n","    for parent in Path.cwd().parents:\n","        sys.path.append(str(parent))\n","\n","from auxiliar_dope.model import DopeNetwork\n","from auxiliar_dope.utils import MultipleVertexJson, save_image\n","import src.args_parser as ar\n","\n","# Import the necessary modules\n","warnings.filterwarnings(\"ignore\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n","\n","full_path = os.getcwd()\n","sys.path.append(full_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgNTEGej6VtD","executionInfo":{"status":"ok","timestamp":1740436195170,"user_tz":360,"elapsed":2244,"user":{"displayName":"HAREL ARATH HERNANDEZ AMEZCUA","userId":"16374506728272450130"}},"outputId":"6ea03750-3b31-46cd-daee-50f4d4acf1f1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ACRP1XYkHA-J","executionInfo":{"status":"ok","timestamp":1740436195175,"user_tz":360,"elapsed":9,"user":{"displayName":"HAREL ARATH HERNANDEZ AMEZCUA","userId":"16374506728272450130"}}},"outputs":[],"source":["# Parse arguments\n","opt = ar.parse_args(full_path, colab)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1740436195220,"user":{"displayName":"HAREL ARATH HERNANDEZ AMEZCUA","userId":"16374506728272450130"},"user_tz":360},"id":"9a31RWTP8d0k","outputId":"cd84786d-261f-482e-846b-cae771ca632c"},"outputs":[{"output_type":"stream","name":"stdout","text":["start: 22:29:54.566151\n"]}],"source":["##################################################\n","# TRAINING CODE MAIN STARTING HERE\n","##################################################\n","\n","print (\"start:\" , datetime.datetime.now().time())\n","\n","if opt.pretrained in ['false', 'False']:\n","\topt.pretrained = False\n","\n","try:\n","    os.makedirs(opt.outf)\n","except OSError:\n","    pass\n","\n","if opt.manualseed is None:\n","    opt.manualseed = random.randint(1, 10000)\n","\n","# save the hyper parameters passed\n","with open (opt.outf+'/header.txt','w') as file:\n","    file.write(str(opt)+\"\\n\")\n","\n","with open (opt.outf+'/header.txt','w') as file:\n","    file.write(str(opt))\n","    file.write(\"seed: \"+ str(opt.manualseed)+'\\n')\n","    with open (opt.outf+'/test_metric.csv','w') as file:\n","        file.write(\"epoch, passed,total \\n\")\n","\n","# set the manual seed.\n","random.seed(opt.manualseed)\n","torch.manual_seed(opt.manualseed)\n","torch.cuda.manual_seed_all(opt.manualseed)\n","\n","additional_targets = {\n","    'centroids': 'keypoints'\n","}\n","\n","def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')\n","\n","def scale_down(x, **kwargs):\n","    return cv2.resize(x, (x.shape[0] // 8, x.shape[1] // 8))\n","\n","\n","img_size = (480,640)\n","\n","mean = [0.45, 0.45, 0.45]\n","std = [0.25, 0.25, 0.25]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3694675372f64273bb4a4ac32399afe4","352720351bcd484b81a490bdf2629e80","1360f1c25be34a0d8e49aa13b48541dc","7e273f133eff450091c2f35b534fe5ba","97d9ba0d24dd42ccb72f44c93f01e33d","cf4933e3634d4a1bb8327d87e58525c1","1906023d590a40bb8f3af2cfd7e31457","bb37e652243f498c8188b7b3071bea46","a421b58d917841d4a4bef94332f75eab","179a62c37b624db0acf81a55d96771df","343da6601add4f738ca3a9efccee5332"]},"id":"oN2AdOmJ8jUU","outputId":"78af9d65-78e1-4317-dd74-80bb6cc6ac76"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["training data: 473 batches\n","testing data: 16 batches\n","Training network pretrained on imagenet.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|██████████| 548M/548M [00:05<00:00, 113MB/s] \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3694675372f64273bb4a4ac32399afe4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n","Guardando model\n"]}],"source":["transform = A.Compose([\n","    A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=0.1, shift_limit=0.1, p=0.1, border_mode=0),\n","\n","    A.RandomCrop(height=img_size[0], width=img_size[1]),\n","\n","    A.IAAAdditiveGaussianNoise(p=0.2),\n","    A.IAAPerspective(p=0.5),\n","\n","    A.OneOf(\n","        [\n","            A.CLAHE(p=1),\n","            A.RandomBrightness(p=1),\n","            A.RandomGamma(p=1),\n","        ],\n","        p=0.9,\n","    ),\n","\n","    A.OneOf(\n","        [\n","            A.IAASharpen(p=1),\n","            A.Blur(blur_limit=3, p=1),\n","            A.MotionBlur(blur_limit=3, p=1),\n","        ],\n","        p=0.9,\n","    ),\n","\n","    A.OneOf(\n","        [\n","            A.RandomContrast(p=1),\n","            A.HueSaturationValue(p=1),\n","        ],\n","        p=0.9,\n","    )],\n","additional_targets=additional_targets,\n","keypoint_params=A.KeypointParams(\"xy\", remove_invisible=False))\n","\n","preprocessing_transform = A.Compose([\n","        A.Normalize(mean=mean, std=std),\n","        A.Lambda(mask=scale_down),\n","        A.Lambda(image=to_tensor, mask=to_tensor)],\n","    additional_targets=additional_targets,\n","    keypoint_params=A.KeypointParams(\"xy\", remove_invisible=False))\n","\n","#load the dataset using the loader in utils_pose\n","trainingdata = None\n","if not opt.data == \"\":\n","    train_dataset = MultipleVertexJson(\n","        root = opt.data,\n","        preprocessing_transform=preprocessing_transform,\n","        objectsofinterest=opt.object,\n","        sigma = opt.sigma,\n","        data_size = opt.datasize,\n","        save = opt.save,\n","        transform = transform,\n","    )\n","\n","    trainingdata = torch.utils.data.DataLoader(train_dataset,\n","        batch_size = opt.subbatchsize,\n","        shuffle = True,\n","        num_workers = opt.workers,\n","        pin_memory = True,\n","        drop_last=True\n","    )\n","\n","    \"\"\"train_dataset.test = True\n","    for i in range(len(trainingdata)):\n","        images = next(iter(trainingdata))\n","\n","        save_image(images['image'],'{}/train_{}.png'.format( opt.outf,str(i).zfill(5)),mean=mean[0],std=std[0])\n","        print (\"Saving batch %d\" % i)\n","    train_dataset.test = False\"\"\"\n","\n","    if opt.save:\n","        print ('things are saved in {}'.format(opt.outf))\n","        quit()\n","\n","\n","testingdata = None\n","if not opt.datatest == \"\":\n","    test_dataset = MultipleVertexJson(\n","            root = opt.datatest,\n","            preprocessing_transform=preprocessing_transform,\n","            objectsofinterest=opt.object,\n","            sigma = opt.sigma,\n","            data_size = opt.datasize,\n","            save = opt.save,\n","            test = True\n","            )\n","\n","    testingdata = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size = opt.subbatchsize // 2,\n","        shuffle = True,\n","        num_workers = opt.workers,\n","        pin_memory = True,\n","        drop_last=True)\n","\n","\n","if not trainingdata is None:\n","    print('training data: {} batches'.format(len(trainingdata)))\n","if not testingdata is None:\n","    print (\"testing data: {} batches\".format(len(testingdata)))\n","\n","net = DopeNetwork(pretrained=opt.pretrained)\n","net = net.to(device)\n","\n","\n","if opt.net != '':\n","    # Load state dict from file\n","    state_dict = torch.load(opt.net, map_location='cuda')\n","\n","    # If the state dict keys start with \"module.\", remove that prefix\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        new_key = k[7:] if k.startswith(\"module.\") else k\n","        new_state_dict[new_key] = v\n","\n","    # Use the new_state_dict directly\n","    net.load_state_dict(new_state_dict)\n","\n","\n","parameters = filter(lambda p: p.requires_grad, net.parameters())\n","optimizer = optim.Adam(parameters,lr=opt.lr)\n","\n","with open (opt.outf+'/loss_train.csv','w') as file:\n","    file.write('epoch,batchid,loss\\n')\n","\n","with open (opt.outf+'/loss_test.csv','w') as file:\n","    file.write('epoch,batchid,loss\\n')\n","\n","nb_update_network = 0\n","\n","def _runnetwork(epoch, loader, train=True, scaler=None, pbar=None):\n","    global nb_update_network\n","    # net\n","    if train:\n","        net.train()\n","    else:\n","        net.eval()\n","\n","    if train:\n","        optimizer.zero_grad()\n","    for batch_idx, targets in enumerate(loader):\n","\n","        data = Variable(targets['image'].to(device).float())\n","\n","        with amp.autocast():\n","            output_belief, output_affinities = net(data)\n","\n","            target_belief = Variable(targets['beliefs'].to(device).float())\n","            target_affinity = Variable(targets['affinities'].to(device).float())\n","\n","            loss = None\n","\n","            for l in output_belief:\n","                if loss is None:\n","                    loss = ((l - target_belief) ** 2).mean()\n","                else:\n","                    loss += ((l - target_belief) ** 2).mean()\n","\n","\n","            # Affinities loss\n","            for l in output_affinities: #output, each belief map layers.\n","                loss_tmp = ((l - target_affinity) * (l-target_affinity)).mean()\n","                loss += loss_tmp\n","\n","        if train:\n","            scaler.scale(loss).backward()\n","            if batch_idx % (opt.batchsize // opt.subbatchsize) == 0:\n","                if train:\n","                    scaler.step(optimizer)\n","                    scaler.update()\n","                    nb_update_network+=1\n","                    optimizer.zero_grad()\n","\n","        if train:\n","            namefile = '/loss_train.csv'\n","        else:\n","            namefile = '/loss_test.csv'\n","\n","        with open (opt.outf+namefile,'a') as file:\n","            s = '{}, {},{:.15f}\\n'.format(\n","                epoch,batch_idx,loss.data.item())\n","            # print (s)\n","            file.write(s)\n","\n","        # break\n","        if not opt.nbupdates is None and nb_update_network > int(opt.nbupdates):\n","            torch.save(net.state_dict(), '{}/net_{}.pth'.format(opt.outf, opt.namefile))\n","            break\n","\n","        if train:\n","            if pbar is not None:\n","                pbar.set_description(\"Training loss: %0.4f (%d/%d)\" % (loss.data.item(), batch_idx, len(loader)))\n","        else:\n","            if pbar is not None:\n","                pbar.set_description(\"Testing loss: %0.4f (%d/%d)\" % (loss.data.item(), batch_idx, len(loader)))\n","        if batch_idx % 10 == 0:\n","          try:\n","            torch.save(net.state_dict(), f'{opt.outf}/net.pth')\n","            print(\"Guardando model\")\n","          except Exception as e:\n","            print(f\"Error saving model at epoch: {e}\")\n","\n","    if train:\n","        optimizer.zero_grad()\n","\n","\n","scaler = amp.GradScaler()\n","torch.backends.cudnn.benchmark = True\n","pbar = tqdm(range(1, opt.epochs + 1))\n","\n","for epoch in pbar:\n","    # Run training and testing as before\n","    if trainingdata is not None:\n","        _runnetwork(epoch, trainingdata, scaler=scaler, pbar=pbar)\n","\n","    if opt.datatest != \"\":\n","        _runnetwork(epoch, testingdata, train=False, pbar=pbar)\n","        if opt.data == \"\":\n","            break  # Exit if only testing\n","    try:\n","        torch.save(net.state_dict(), f'{opt.outf}/net_{opt.namefile}_{epoch}.pth')\n","    except Exception as e:\n","        print(f\"Error saving model at epoch {epoch}: {e}\")\n","\n","    # Stop training if nb_update_network exceeds the limit\n","    if opt.nbupdates is not None and nb_update_network > int(opt.nbupdates):\n","        break\n","\n","print(\"end:\", datetime.datetime.now().time())"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python (dope_venv)","language":"python","name":"dope_venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3694675372f64273bb4a4ac32399afe4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_352720351bcd484b81a490bdf2629e80","IPY_MODEL_1360f1c25be34a0d8e49aa13b48541dc","IPY_MODEL_7e273f133eff450091c2f35b534fe5ba"],"layout":"IPY_MODEL_97d9ba0d24dd42ccb72f44c93f01e33d"}},"352720351bcd484b81a490bdf2629e80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf4933e3634d4a1bb8327d87e58525c1","placeholder":"​","style":"IPY_MODEL_1906023d590a40bb8f3af2cfd7e31457","value":"Training loss: 0.0020 (157/473):  40%"}},"1360f1c25be34a0d8e49aa13b48541dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb37e652243f498c8188b7b3071bea46","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a421b58d917841d4a4bef94332f75eab","value":4}},"7e273f133eff450091c2f35b534fe5ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_179a62c37b624db0acf81a55d96771df","placeholder":"​","style":"IPY_MODEL_343da6601add4f738ca3a9efccee5332","value":" 4/10 [3:14:00&lt;3:40:24, 2204.01s/it]"}},"97d9ba0d24dd42ccb72f44c93f01e33d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf4933e3634d4a1bb8327d87e58525c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1906023d590a40bb8f3af2cfd7e31457":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb37e652243f498c8188b7b3071bea46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a421b58d917841d4a4bef94332f75eab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"179a62c37b624db0acf81a55d96771df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"343da6601add4f738ca3a9efccee5332":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}